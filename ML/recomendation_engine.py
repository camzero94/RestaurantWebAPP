# -*- coding: utf-8 -*-
"""Recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1srgA8EK1wnT2o5w_Wy7nQGEgCNrT3Qtj
"""

!pip list

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import pairwise_distances
from sklearn.metrics import mean_squared_error
from math import sqrt

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!pwd

interactionsDataset = pd.read_csv('drive/MyDrive/Recommendation/DataSetFood/interactions_train.csv')
rawDataset = pd.read_csv('drive/MyDrive/Recommendation/DataSetFood/RAW_recipes.csv')

interactionsDataset.info()
rawDataset.info()

"""#Show Distribution of Ratings (Bar Chart)"""

interactionsDataset.rating.value_counts().plot(kind = 'bar', fontsize = 16,figsize = (5, 5)).set_title('Distribution of Rating based on Users Interactions ',
                                                         fontsize = 18, ha = 'center', va = 'bottom')

df = interactionsDataset.drop(['date','u','i'],axis=1) 
df

"""#The Top 10000 Users and Recipes 



"""

gp_10000_users = df.groupby(['user_id'], as_index = False, sort = False).agg({'recipe_id':'count'}).reset_index(drop = True)
gp_10000_users = gp_10000_users.rename(columns = {'recipe_id':'reviews'})
gp_10000_users = gp_10000_users.sort_values('reviews', ascending = False).iloc[:10000:]
gp_10000_users

gp_10000_items = df.groupby(['recipe_id'], as_index = False, sort = False).agg({'user_id':'count'}).reset_index(drop = True)
gp_10000_items = gp_10000_items.rename(columns = {'user_id':'reviews'})
gp_10000_items = gp_10000_items.sort_values('reviews', ascending = False).iloc[:10000,:]
gp_10000_items

gp_10000_mean = gp_10000_items['reviews'].mean()
gp_10000_mean

items_users =pd.merge(df.merge(gp_10000_users).drop(['reviews'], axis = 1),gp_10000_items ).drop(['reviews'], axis = 1)
items_users

print('unique users:',len(items_users.user_id.unique()))
print('unique recipes:',len(items_users.recipe_id.unique()))

user_group = items_users.groupby(['user_id'], as_index = False, sort = False).agg({'recipe_id':'count'}).reset_index(drop = True)
user_group = user_group.rename(columns = {'recipe_id':'reviews'})

item_group = items_users.groupby(['recipe_id'], as_index = False, sort = False).agg({'user_id':'count'}).reset_index(drop = True)
item_group = item_group.rename(columns = {'user_id':'reviews'})

display(user_group[['reviews']].describe())
display(item_group[['reviews']].describe())

items_users.rating.value_counts().plot(kind = 'bar', fontsize = 14, figsize = (5,5)).set_title('Distribution of Rating',fontsize = 16, ha = 'center', va = 'bottom')

"""#Problem Index Out of Bound. Assign new IDs to the qualified users and recipes"""

new_userID = dict(zip(list(items_users['user_id'].unique()),list(range(len(items_users['user_id'].unique())))))
display(new_userID)

new_recipeID = dict(zip(list(items_users['recipe_id'].unique()),list(range(len(items_users['recipe_id'].unique())))))
display(new_recipeID)

df = items_users.replace({'user_id': new_userID, 'recipe_id': new_recipeID})
df

print('The recipes without names: ', rawDataset['id'][rawDataset['name'].isnull()].values[0])

display(df[df['recipe_id'] == rawDataset['id'][rawDataset['name'].isnull()].values[0]])

recipe = rawDataset[['name', 'id', 'ingredients']].merge(items_users[['recipe_id']], 
                                                left_on = 'id', right_on = 'recipe_id', 
                                                how = 'right').drop(['id'], axis = 1).drop_duplicates().reset_index(drop = True)

recipe

mean = df.groupby(['user_id'], as_index = False, sort = False).mean().rename(columns = {'rating':'rating_mean'})
df = df.merge(mean[['user_id','rating_mean']], how = 'left')
df.insert(2, 'rating_adjusted', df['rating'] - df['rating_mean'])
df

"""#Split datasets Train and Test Datasets"""

train_data, test_data = train_test_split(df, test_size = 0.25)
n_users = df.user_id.unique()
n_items = df.recipe_id.unique()
train_data_matrix = np.zeros((n_users.shape[0], n_items.shape[0]))

for row in train_data.itertuples():
    train_data_matrix[row[1]-1, row[2]-1] = row[3]
display(train_data_matrix.shape)
display(train_data_matrix)

test_data_matrix = np.zeros((n_users.shape[0], n_items.shape[0]))
for row in test_data.itertuples():
    test_data_matrix[row[1]-1, row[2]-1] = row[3]
display(test_data_matrix.shape)
display(test_data_matrix)

"""#Calculate Centered Cosine Similarity (Pearson Correlation)

## There are two major types of memory-based collaborative filtering.
* **User-based**: “Users who are similar to you also like …”
* **Item-based**: “Users who like this item also like …”

## Center Cosine Similarity fot User-Based
"""

similarity_user= 1 - pairwise_distances(train_data_matrix, metric = 'cosine')

display(similarity_user.shape)
display(similarity_user)

"""## Center Cosine Similarity fot Item-Based"""

similarity_item= 1 - pairwise_distances(train_data_matrix.T, metric = 'cosine')

display(similarity_item.shape)
display(similarity_item)

"""# Prediction

## Recommend the recipes that are liked by the users who are similar to me.
"""

def predict(ratings,similarity,_type="user"):
    if _type == 'user':
      pred = similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis = np.newaxis)])
  
    elif _type == 'item':
      pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis = 1)]) 
      
    return pred

"""## Prediction by using User Similarity"""

user_pred = predict(train_data_matrix, similarity_user, _type = 'user')
display(user_pred.shape)                       
display(user_pred)

user_pred_df = pd.DataFrame(user_pred, columns = list(n_items))
print(user_pred_df.shape,user_pred.shape,n_items.shape)
user_pred_df.insert(0, 'user_id', list(n_users))

user_pred_df

"""## Prediction by using Item Similarity"""

item_pred = predict(train_data_matrix, similarity_item, _type = 'item')
display(item_pred.shape)
display(item_pred)

item_pred_df = pd.DataFrame(item_pred, columns = list(n_items))
item_pred_df.insert(0, 'user_id', list(n_users))

item_pred_df

"""# Evaluation by RMSE(Root Square Mean Root)"""

from sklearn.metrics import mean_squared_error
from math import sqrt
def RMSE(prediction, ground_truth):
    prediction = prediction[ground_truth.nonzero()].flatten()
    ground_truth = ground_truth[ground_truth.nonzero()].flatten()
    
    return sqrt(mean_squared_error(prediction, ground_truth))
user_RMSE = RMSE(user_pred, test_data_matrix)
item_RMSE = RMSE(item_pred, test_data_matrix)
print('user_RMSE = {}'.format(user_RMSE))
print('item_RMSE = {}'.format(item_RMSE))

"""# Recommendation Function User-Based Collaborative Filtering"""

def recommend(user_id,top_n=10):
    for old_user, new_user in new_userID.items():
      if user_id == new_user:
          print(f'Top {top_n} Recommended Recipes for Original User ID: {old_user}\n')
  
    movie_rated = list(df['recipe_id'].loc[df['user_id'] == user_id])
    _all = user_pred_df.loc[user_pred_df['user_id'] == user_id].copy()
    _all.drop(user_pred_df[movie_rated], axis = 1, inplace = True)
    unwatch_sorted = _all.iloc[:,1:].sort_values(by = _all.index[0], axis = 1, ascending = False)
    dict_top_n = unwatch_sorted.iloc[:, :top_n].to_dict(orient = 'records')

    i = 1
    for recipe_id in list(dict_top_n[0].keys()):
        for old_recipe, new_recipe in new_recipeID.items():
            if recipe_id == new_recipe:
                name = recipe[recipe['recipe_id'] == old_recipe]['name'].values[0]
                ingredients = recipe[recipe['recipe_id'] == old_recipe]['ingredients'].values[0]

                print(f'Top {i} Original Recipe ID: {old_recipe} - {name}\n Ingredients: {ingredients}\n')
                
                i += 1
                
    return dict_top_n[0]

Rec_UserBased = recommend(702)

Rec_UserBased = recommend(100,5)